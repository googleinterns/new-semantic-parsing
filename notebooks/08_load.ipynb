{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from new_semantic_parsing import EncoderDecoderWPointerModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = 'output_dir'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab_size = 23\n",
    "tgt_vocab_size = 17\n",
    "\n",
    "model = EncoderDecoderWPointerModel.from_parameters(\n",
    "    layers=1,\n",
    "    hidden=32,\n",
    "    heads=2,\n",
    "    src_vocab_size=src_vocab_size,\n",
    "    tgt_vocab_size=tgt_vocab_size,\n",
    "    max_src_len=7,\n",
    "    hidden_dropout_prob=0,\n",
    "    attention_probs_dropout_prob=0,\n",
    ")\n",
    "\n",
    "input_ids = torch.randint(src_vocab_size, size=(3, 7))\n",
    "tgt_sequence = torch.randint(tgt_vocab_size, size=(3, 11))\n",
    "decoder_input_ids = tgt_sequence[:, :-1].contiguous()\n",
    "labels = tgt_sequence[:, 1:].contiguous()\n",
    "\n",
    "expected_output = model(input_ids=input_ids, decoder_input_ids=decoder_input_ids, labels=labels)\n",
    "\n",
    "# os.mkdir(output_dir)\n",
    "model.save_pretrained(output_dir)\n",
    "\n",
    "random_model = EncoderDecoderWPointerModel.from_parameters(\n",
    "    layers=1,\n",
    "    hidden=32,\n",
    "    heads=2,\n",
    "    src_vocab_size=src_vocab_size,\n",
    "    tgt_vocab_size=tgt_vocab_size,\n",
    "    max_src_len=7,\n",
    ")\n",
    "loaded_model, info = EncoderDecoderWPointerModel.from_pretrained(output_dir, output_loading_info=True)\n",
    "\n",
    "output = loaded_model(input_ids=input_ids, decoder_input_ids=decoder_input_ids, labels=labels)\n",
    "random_output = random_model(input_ids=input_ids, decoder_input_ids=decoder_input_ids, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'missing_keys': [], 'unexpected_keys': [], 'error_msgs': []}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check that the configs are equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = model.config.to_dict()\n",
    "c2 = loaded_model.config.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(new_semantic_parsing.modeling_encoder_decoder_wpointer.EncoderDecoderWPointerModel,\n",
       " new_semantic_parsing.modeling_encoder_decoder_wpointer.EncoderDecoderWPointerModel)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model), type(loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "dkeys = set(c1.keys()).symmetric_difference(set(c2.keys()))\n",
    "print([(k, c1.get(k, None), c2.get(k, None)) for k in dkeys])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in c1.keys():\n",
    "    if c1[k] != c2[k]:\n",
    "        print(k, c1[k], c2[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(len(output) == len(expected_output))\n",
    "print(torch.allclose(expected_output[0], output[0]))\n",
    "print(torch.allclose(expected_output[1], output[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.3304, -0.4807, -0.3249, -0.3067, -1.0206,  0.7124,  0.0791,  0.3639,\n",
       "          0.7486,  0.1944, -0.5413, -0.4551,  0.0462,  0.2680,  1.3111,  0.1761,\n",
       "          0.8181,  2.2675, -0.4928, -2.3798, -1.4215,  2.4018, -0.4288, -2.0853],\n",
       "        grad_fn=<SelectBackward>),\n",
       " tensor([-0.3304, -0.4807, -0.3249, -0.3067, -1.0206,  0.7124,  0.0791,  0.3639,\n",
       "          0.7486,  0.1944, -0.5413, -0.4551,  0.0462,  0.2680,  1.3111,  0.1761,\n",
       "          0.8181,  2.2675, -0.4928, -2.3798, -1.4215,  2.4018, -0.4288, -2.0853],\n",
       "        grad_fn=<SelectBackward>),\n",
       " tensor([-0.1568, -0.1964,  0.0501,  1.2691, -0.0596, -0.3503, -0.5219,  0.4210,\n",
       "         -0.3945, -0.4205, -0.3819,  0.3941, -0.5649, -0.3812, -1.0649,  0.0159,\n",
       "         -1.1970, -1.1131, -1.3002, -1.9903, -2.3364, -2.4054, -2.1643,  2.3802],\n",
       "        grad_fn=<SelectBackward>))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_output[1][0][0], output[1][0][0], random_output[1][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0057, -0.0163, -0.0330, -0.0056,  0.0153,  0.0070, -0.0099,  0.0141,\n",
      "         0.0017,  0.0096, -0.0309,  0.0080, -0.0171, -0.0065,  0.0125,  0.0205,\n",
      "         0.0158,  0.0038,  0.0385, -0.0065, -0.0018,  0.0198, -0.0163, -0.0304,\n",
      "         0.0154,  0.0156,  0.0013,  0.0186, -0.0045,  0.0077,  0.0108,  0.0017],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([ 0.0057, -0.0163, -0.0330, -0.0056,  0.0153,  0.0070, -0.0099,  0.0141,\n",
      "         0.0017,  0.0096, -0.0309,  0.0080, -0.0171, -0.0065,  0.0125,  0.0205,\n",
      "         0.0158,  0.0038,  0.0385, -0.0065, -0.0018,  0.0198, -0.0163, -0.0304,\n",
      "         0.0154,  0.0156,  0.0013,  0.0186, -0.0045,  0.0077,  0.0108,  0.0017],\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(model.encoder.embeddings.word_embeddings.weight[5]),\n",
    "print(loaded_model.encoder.embeddings.word_embeddings.weight[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter = next(model.parameters())\n",
    "loaded_parameter = next(loaded_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (p1, p2) in enumerate(zip(model.parameters(), loaded_model.parameters())):\n",
    "    assert torch.allclose(p1, p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
